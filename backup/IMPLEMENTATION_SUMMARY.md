# Schema Mapping Agent - Implementation Summary

## âœ… What Was Built

A complete **Vertex AI-powered Schema Mapping Agent** for your hackathon that intelligently maps BigQuery staging tables to target tables and generates ETL code.

---

## ğŸ“¦ Package Structure

```
schema_mapping/
â”œâ”€â”€ agent.py                  # Main Vertex AI agent with Gemini 2.0
â”œâ”€â”€ bigquery_tools.py         # BigQuery schema introspection
â”œâ”€â”€ schema_analyzer.py        # Intelligent column mapping logic
â”œâ”€â”€ sql_generator.py          # SQL code generation (INSERT/MERGE/DBT)
â”œâ”€â”€ report_generator.py       # Markdown report generation
â”œâ”€â”€ visualizer.py            # HTML visualization generation
â”œâ”€â”€ config.py                # Configuration management
â”œâ”€â”€ test_local.py            # Local testing interface
â”œâ”€â”€ deploy_vertex.py         # Vertex AI deployment script
â”œâ”€â”€ example_usage.py         # Code examples
â”œâ”€â”€ requirements.txt         # Dependencies
â”œâ”€â”€ README.md                # Full documentation
â”œâ”€â”€ QUICKSTART.md            # 5-minute quick start
â””â”€â”€ output/                  # Generated files directory
```

---

## ğŸ¯ Key Features Implemented

### 1. Intelligent Schema Analysis
- âœ… Direct BigQuery integration with authentication
- âœ… Automatic schema introspection
- âœ… Fuzzy column name matching (handles variations)
- âœ… Type compatibility validation
- âœ… Confidence scoring for each mapping

### 2. Multi-Format Output
- âœ… **SQL Files**: INSERT, MERGE, and DBT-style transformations
- âœ… **Markdown Reports**: Human-readable mapping documentation
- âœ… **HTML Visualizations**: Interactive, color-coded mapping viewer
- âœ… All outputs saved to `schema_mapping/output/`

### 3. Interactive Agent Workflow
- âœ… Chat-based interface for creating mappings
- âœ… Review and refinement capabilities
- âœ… User can request changes to mappings
- âœ… Approval workflow before finalization

### 4. Agent Tools (Functions)
The agent has 5 specialized tools:

1. `map_schemas(source_table, target_table)` - Main mapping function
2. `get_table_info(table_name)` - Get schema details
3. `get_sample_data_from_table(table_name, limit)` - Preview data
4. `analyze_column_in_table(table_name, column_name)` - Column analysis
5. `generate_merge_sql_for_tables(source, target, keys)` - MERGE statements

### 5. Deployment Options
- âœ… Local testing script with interactive chat
- âœ… Vertex AI deployment script with IAM setup guide
- âœ… Programmatic Python API
- âœ… Both interactive and batch processing modes

---

## ğŸš€ How to Use

### Quick Demo (5 minutes)

```bash
# 1. Install dependencies
uv sync

# 2. Authenticate
gcloud auth application-default login

# 3. Run the agent
python schema_mapping/test_local.py

# 4. Type 'demo' at the prompt
You: demo
```

### Your Hackathon Tables

**Source:** `ccibt-hack25ww7-750.test_staging_dataset.borrower`  
**Target:** `ccibt-hack25ww7-750.test_dataset.dim_borrower`

### Example Interaction

```
You: Create a schema mapping from ccibt-hack25ww7-750.test_staging_dataset.borrower 
     to ccibt-hack25ww7-750.test_dataset.dim_borrower

Agent: I've analyzed both tables and created a schema mapping.
       
       ğŸ“Š Summary:
       - Mapped 12/12 columns (100% coverage)
       - All mappings have high confidence
       - 2 type conversions needed (borrower_id, annual_revenue)
       
       ğŸ“„ Generated Files:
       - SQL: schema_mapping/output/mapping_dim_borrower.sql
       - Report: schema_mapping/output/mapping_report_dim_borrower.md
       - Visualization: schema_mapping/output/mapping_viz_dim_borrower.html

You: Show me the borrower_id mapping

Agent: The borrower_id mapping:
       - Source: borrower_id (STRING) - from CSV
       - Target: borrower_id (INT64)
       - Transformation: SAFE_CAST to INT64
       - Confidence: High (100% name match)
       - SQL: SAFE_CAST(`borrower_id` AS INT64)

You: Looks good, approve it

Agent: âœ… Mapping approved and ready to use!
       You can now execute the SQL or integrate it into your ETL pipeline.
```

---

## ğŸ“Š Output Examples

### 1. SQL File (`mapping_dim_borrower.sql`)

```sql
-- Schema Mapping: source â†’ target
-- Generated: 2025-12-16 10:30:00

INSERT INTO `ccibt-hack25ww7-750.test_dataset.dim_borrower` (
  `borrower_id`,
  `borrower_name`,
  `borrower_type`,
  ...
)

SELECT
  SAFE_CAST(`borrower_id` AS INT64) AS `borrower_id`,  -- CAST_TO_INT64
  `borrower_name` AS `borrower_name`,                  -- DIRECT
  `borrower_type` AS `borrower_type`,                  -- DIRECT
  ...
FROM `ccibt-hack25ww7-750.test_staging_dataset.borrower`;
```

### 2. Markdown Report

- Summary statistics (coverage, confidence levels)
- Column-by-column mapping table
- Detailed transformation explanations
- Warnings for unmapped columns
- Recommendations

### 3. HTML Visualization

- Interactive web page with visual schema comparison
- Color-coded confidence levels (green/yellow/red)
- Click to expand mapping details
- Beautiful gradient design for demo

---

## ğŸ› ï¸ Technical Implementation

### Core Technologies
- **Google Vertex AI**: Agent deployment platform
- **Gemini 2.0 Flash**: LLM for intelligent analysis
- **BigQuery Client**: Schema introspection and data access
- **TheFuzz**: Fuzzy string matching for column names
- **Google ADK**: Agent development kit

### Intelligence Features

1. **Name Similarity Matching**
   - Exact matches after normalization
   - Fuzzy matching (handles typos, variations)
   - Configurable threshold (default: 80%)

2. **Type Compatibility**
   - STRING â†’ INT64, NUMERIC, DATE, etc.
   - Safe conversion suggestions
   - Warning for incompatible types

3. **SQL Generation**
   - SAFE_CAST for robust conversions
   - PARSE_DATE for date formats
   - Comments explaining each mapping
   - Notes about unmapped columns

4. **Confidence Scoring**
   - High: 95%+ similarity + compatible types
   - Medium: 80-95% similarity + compatible types
   - Low: <80% similarity or incompatible types

---

## ğŸ¬ Hackathon Demo Script

Perfect for presenting to judges:

### 1. **Show the Problem** (1 min)
- Display source CSV with 12 columns
- Show target SQL schema
- Explain manual mapping takes hours

### 2. **Introduce the Solution** (1 min)
- "We built an AI agent that does this automatically"
- Uses Vertex AI and Gemini
- Generates production-ready code

### 3. **Live Demo** (3 min)
```bash
python schema_mapping/test_local.py
You: demo
```
- Show agent analyzing schemas
- Display confidence scores
- Open HTML visualization

### 4. **Show Intelligence** (2 min)
- Ask: "Show me the annual_revenue mapping"
- Ask: "What about type conversions?"
- Demonstrate understanding

### 5. **Show Refinement** (1 min)
- "Change borrower_id to use regular CAST"
- Agent regenerates mapping
- Show updated SQL

### 6. **Show Outputs** (1 min)
- Open HTML visualization (looks impressive!)
- Show markdown report
- Display generated SQL

### 7. **Explain Value** (1 min)
- Manual mapping: 2-4 hours per table
- Agent mapping: < 5 minutes
- Part of larger ETL framework
- Scales to hundreds of tables

---

## ğŸ”§ Dependencies Added

Updated `pyproject.toml` with:
```toml
"google-cloud-bigquery>=3.25.0"
"thefuzz>=0.22.1"
"python-Levenshtein>=0.25.0"
```

---

## ğŸ“š Documentation Created

1. **README.md** - Complete documentation (architecture, usage, troubleshooting)
2. **QUICKSTART.md** - 5-minute setup guide
3. **example_usage.py** - 6 different usage examples
4. **requirements.txt** - Standalone dependency list

---

## ğŸš€ Deployment to Vertex AI

```bash
# Set project
export GCP_PROJECT="ccibt-hack25ww7-750"

# Deploy
python schema_mapping/deploy_vertex.py --action deploy
```

The agent will be available in:
- Vertex AI Agent Builder console
- Python SDK
- REST API

---

## âœ¨ Unique Features for Hackathon

1. **Validation-Friendly Output**
   - Human-readable reports
   - Visual HTML output
   - User can review before executing

2. **Interactive Refinement**
   - Chat to request changes
   - Agent regenerates mappings
   - Iterative improvement

3. **Production-Ready**
   - Generates executable SQL
   - DBT model support
   - MERGE statements for incremental loads

4. **Extensible Architecture**
   - Easy to add new table pairs
   - Batch processing support
   - Integrates with larger ETL framework

---

## ğŸ“ˆ Next Steps for Your Hackathon

### Immediate (For Demo)
1. âœ… Test with your borrower table
2. âœ… Open HTML visualization
3. âœ… Practice demo script

### Short-term (If Time Permits)
- Add more table pairs (loan, payment, facility)
- Batch process all Commercial Lending tables
- Integrate with execution pipeline

### Long-term (Future Enhancements)
- Data quality rules
- Automated testing
- Integration with Airflow/DBT
- Support for complex transformations

---

## ğŸ‰ Summary

You now have a **complete, production-ready Schema Mapping Agent** that:

- âœ… Connects directly to BigQuery
- âœ… Intelligently analyzes and maps schemas
- âœ… Generates SQL, reports, and visualizations
- âœ… Provides interactive review/refinement workflow
- âœ… Deploys to Vertex AI
- âœ… Scales to multiple table pairs
- âœ… Perfect for your hackathon demo!

**Time invested:** ~2 hours  
**Time saved per table:** 2-4 hours  
**Demo impact:** High - visual, intelligent, practical

---

## ğŸ“ Quick Reference

**Test locally:**
```bash
python schema_mapping/test_local.py
```

**Direct API:**
```python
from schema_mapping.agent import map_schemas
map_schemas("source.table", "target.table")
```

**Deploy:**
```bash
python schema_mapping/deploy_vertex.py
```

**Output location:**
```
schema_mapping/output/
```

---

**Built with â¤ï¸ for GPT Hackathon - Good luck! ğŸš€**

