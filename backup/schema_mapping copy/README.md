# Schema Mapping Agent

Automatically generates schema mappings between BigQuery staging and target datasets using Google ADK and Gemini 2.5 Flash.

## What It Does

1. **Fetches Schemas**: Reads table and column metadata from BigQuery datasets
2. **AI Mapping**: Uses Gemini 2.5 Flash to intelligently map:
   - Source tables â†’ Target tables
   - Source columns â†’ Target columns
   - Type conversions needed
   - Validation rules (NOT_NULL, NUMERIC, RANGE)
   - Primary keys and uniqueness constraints
3. **Outputs JSON**: Saves structured mapping configuration

## Quick Start

### Option 1: Interactive with ADK (Recommended)

```bash
# Run as an interactive agent
adk run agents/schema_mapping

# Then chat with the agent:
# > Generate a mapping between worldbank_staging_dataset and worldbank_target_dataset in FIX mode
```

**ðŸ“– See [QUICKSTART_ADK.md](QUICKSTART_ADK.md) for detailed ADK usage**

### Option 2: Command Line Interface

```bash
# Install dependencies (if not already installed)
pip install google-cloud-bigquery google-adk python-dotenv

# Run the mapper
python agents/schema_mapping/run_schema_mapper.py \
    --source worldbank_staging_dataset \
    --target worldbank_target_dataset \
    --output worldbank_mapping.json
```

### Option 3: Test Locally

```bash
cd agents/schema_mapping
python test_local.py
```

## Configuration

Uses the same `.env` file as validation agent:

```bash
# agents/validation/.env
GCP_PROJECT_ID=ccibt-hack25ww7-750
GOOGLE_CLOUD_PROJECT=ccibt-hack25ww7-750
GOOGLE_CLOUD_LOCATION=us-central1
GOOGLE_GENAI_USE_VERTEXAI=1
```

## Output Format

The generated JSON follows this structure:

```json
{
  "metadata": {
    "source_dataset": "project.staging",
    "target_dataset": "project.target",
    "generated_at": "2025-12-16T10:30:00Z",
    "confidence": "high"
  },
  "mappings": [
    {
      "source_table": "staging.countries",
      "target_table": "target.countries",
      "match_confidence": 1.0,
      "column_mappings": [
        {
          "source_column": "country_code",
          "target_column": "country_code",
          "source_type": "STRING",
          "target_type": "STRING",
          "type_conversion_needed": false,
          "transformation": null,
          "notes": "Direct mapping"
        }
      ],
      "validation_rules": [
        {
          "column": "country_code",
          "type": "NOT_NULL",
          "reason": "Target column is REQUIRED"
        }
      ],
      "primary_key": ["country_code"],
      "uniqueness_constraints": ["country_code"]
    }
  ]
}
```

## How It Works

### 1. Schema Fetching
```python
from agents.schema_mapping.schema_mapper import fetch_dataset_schemas

schemas = fetch_dataset_schemas("worldbank_staging_dataset")
# Returns: {table_name: {columns: [...], num_rows: ...}}
```

### 2. LLM Mapping
The agent uses Gemini 2.0 Flash with this instruction set:
- Match tables by name similarity
- Map columns considering types and semantics
- Generate validation rules from target schema constraints
- Identify primary keys and uniqueness requirements

### 3. Output Tool
The LLM calls `submit_schema_mapping(mapping_json)` when complete.

## Integration with Validation Agent

The output JSON can be used directly by the validation agent:

```python
# Generated by schema mapper
with open("worldbank_mapping.json") as f:
    mapping = json.load(f)

# Use in validation
for table_mapping in mapping["mappings"]:
    rules = table_mapping["validation_rules"]
    validate_data(table_mapping["target_table"], json.dumps(rules), "REPORT")
```

## CLI Options

```bash
python agents/schema_mapping/run_schema_mapper.py --help

Options:
  --source TEXT   Source dataset name (required)
  --target TEXT   Target dataset name (required)
  --output TEXT   Output JSON filename (default: schema_mapping_output.json)
```

## Examples

### Example 1: World Bank Data
```bash
python agents/schema_mapping/run_schema_mapper.py \
    --source worldbank_staging_dataset \
    --target worldbank_target_dataset \
    --output worldbank_mapping.json
```

### Example 2: Test Datasets
```bash
python agents/schema_mapping/run_schema_mapper.py \
    --source test_staging_dataset \
    --target test_target_dataset \
    --output test_mapping.json
```

## Features

- âœ… Automatic table matching by name similarity
- âœ… Intelligent column mapping considering types
- âœ… Type conversion detection (STRING â†’ INT, etc.)
- âœ… Auto-generated validation rules from target schema
- âœ… Primary key detection
- âœ… Uniqueness constraint identification
- âœ… Range validation for numeric fields
- âœ… Unmapped column detection
- âœ… Confidence scoring for matches

## Model Used

**Gemini 2.5 Flash** (`gemini-2.5-flash`)
- Fast inference
- Excellent at structured output (JSON)
- Understands schema semantics
- Cost-effective for repeated runs
- Enhanced reasoning capabilities

## Troubleshooting

### Error: "Dataset not found"
- Verify dataset exists in BigQuery
- Check GCP project ID in `.env`
- Ensure you have permissions to read schemas

### Error: "Agent not responding"
- Check Vertex AI is enabled in your project
- Verify `GOOGLE_GENAI_USE_VERTEXAI=1` in `.env`
- Ensure you're authenticated (`gcloud auth application-default login`)

### Invalid JSON output
- LLM occasionally generates malformed JSON
- Re-run the command (results may vary slightly)
- Check agent instruction prompt in `schema_mapper.py`

## Files

- `agent.py` - ADK agent definition (for `adk run`)
- `schema_mapper.py` - Core mapping logic
- `run_schema_mapper.py` - CLI interface
- `api.py` - FastAPI REST API wrapper
- `test_local.py` - Local testing script
- `README.md` - This file
- `README_ADK.md` - ADK integration guide
- `QUICKSTART_ADK.md` - Quick start with ADK
- `__init__.py` - Package exports

## Next Steps

After generating the mapping:

1. **Review Output**: Check `worldbank_mapping.json` for accuracy
2. **Adjust Rules**: Manually edit validation rules if needed
3. **Run Validation**: Use with validation agent to check data quality
4. **Generate ETL**: Use mapping to create transformation SQL (future feature)
